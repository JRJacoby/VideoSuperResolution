{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import video_data_classes as vid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd.profiler as profiler\n",
    "import torch\n",
    "import h5py\n",
    "import utils\n",
    "from time import perf_counter\n",
    "from skimage import io\n",
    "from importlib import reload\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperResNetwork, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Conv2d(6, 8, (3, 3))\n",
    "        self.output_layer = nn.ConvTranspose2d(8, 3, (3, 3))\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        first_input = x[0, :, :, :, :]\n",
    "        sequence_length = x.shape[0]\n",
    "        \n",
    "        y = self.input_layer(torch.cat([first_input, torch.zeros_like(first_input)], dim=1)) # concatenate the first input with zeros in the channel dimension\n",
    "        y = self.activation(y)\n",
    "        y = self.output_layer(y)\n",
    "        y = torch.sigmoid(y)\n",
    "        output = torch.unsqueeze(y, 0)\n",
    "        \n",
    "        for i in range(1, sequence_length):\n",
    "            y = self.input_layer(torch.cat([x[i, :, :, :, :], output[i - 1, :, :, :, :]], dim=1))\n",
    "            y = self.activation(y)\n",
    "            y = self.output_layer(y)\n",
    "            y = torch.sigmoid(y)\n",
    "            output = torch.cat([output, torch.unsqueeze(y, 0)], dim=0)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network, loss function, and optimizer\n",
    "\n",
    "network = SuperResNetwork()\n",
    "network.to('cuda:0')\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Rprop(network.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'dataset' represents a dataset of short video samples\n",
    "\n",
    "video_directory = r'C:\\Users\\John\\PythonVenvs\\VideoSuperResolution\\Scripts\\Raw Data\\Raw, Half-Size, and PNGs'\n",
    "dataset = vid.VideoDataset(video_directory, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "# Creates an hdf5 file of video data for fast i/o during training\n",
    "\n",
    "utils.generate_hdf5(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\john\\pythonvenvs\\videosuperresolution\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(r'E:\\hdf5_file.hdf5', 'r') as data:\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    train_batch_size = 4\n",
    "    val_batch_size = 2\n",
    "    total_batch_size = train_batch_size + val_batch_size\n",
    "    batch_indices = utils.make_batches(len(dataset), total_batch_size)\n",
    "\n",
    "    x = torch.empty(dataset.sequence_length, total_batch_size, 3, 64, 64, device='cuda:0')\n",
    "    y = torch.empty(dataset.sequence_length, total_batch_size, 3, 256, 256, device='cuda:0')\n",
    "\n",
    "    for i in list(range(batch_indices.shape[0])):\n",
    "        x[...] = torch.tensor(data['X'][batch_indices[i, :], ...].transpose(1, 0, 2, 3, 4), device='cuda:0') / 255.0 # shape [dataset.sequence_length, total_batch_size, c, h, w]\n",
    "        y[...] = torch.tensor(data['Y'][batch_indices[i, :], ...].transpose(1, 0, 2, 3, 4), device='cuda:0') / 255.0 # shape [dataset.sequence_length, total_batch_size, c, h, w]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = network(x[:, :train_batch_size, ...])\n",
    "        loss = criterion(output, y[:, :train_batch_size, ...])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_output = network(x[:, train_batch_size:, ...])\n",
    "        val_loss = criterion(val_output, y[:, train_batch_size:, ...])\n",
    "\n",
    "        writer.add_scalar('Loss/Train', loss, i)\n",
    "        writer.add_scalar('Loss/Validation', val_loss, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\John\\\\PythonVenvs\\\\VideoSuperResolution\\\\Scripts\\\\VideoSuperResolution\\\\utils.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(utils)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
