{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import video_data_classes as vid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from skimage import io\n",
    "from importlib import reload\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperResNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SuperResNetwork, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Conv2d(3, 8, (3, 3))\n",
    "        self.output_layer = nn.ConvTranspose2d(8, 3, (3, 3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        first_input = x[0, :, :, :, :]\n",
    "        first_input = first_input.double()\n",
    "        sequence_length = x.shape[0]\n",
    "        set_trace()\n",
    "        y = self.input_layer(torch.cat([first_input, torch.zeros_like(first_input)], dim=2)) # concatenate the first input with zeros in the channel dimension\n",
    "        y = F.ReLU(y)\n",
    "        y = self.output_layer(y)\n",
    "        output = torch.reshape(y, (3, 256, 256))\n",
    "        \n",
    "        for i in range(1, sequence_length):\n",
    "            y = self.input_layer(torch.cat([x[i:i+1, :, :, :, :], output[i - 1:i, :, :, :, :]], dim=2))\n",
    "            y = F.ReLU(y)\n",
    "            y = self.output_layer(y)\n",
    "            output = torch.cat([output, torch.reshape(y, (3, 256, 256))], dim=0)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = SuperResNetwork()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Rprop(network.parameters())\n",
    "\n",
    "video_directory = r'C:\\Users\\John\\PythonVenvs\\VideoSuperResolution\\Scripts\\Raw Data\\Raw, Half-Size, and PNGs'\n",
    "preprocess = transforms.Compose([vid.LightenImageTransformer(),\n",
    "                                vid.MinMaxTransformer()])\n",
    "dataset = vid.VideoDataset(video_directory, 10, transform=preprocess)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    train_x = torch.stack(data['X']).permute(0, 1, 4, 3, 2) #seq, batch, c, h, w\n",
    "    train_y = torch.stack(data['Y']).permute(0, 1, 4, 3, 2)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = network(train_x)\n",
    "    loss = criterion(outputs, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = vid.VideoDataset(r'C:\\Users\\John\\PythonVenvs\\VideoSuperResolution\\Scripts\\Raw Data\\Raw, Half-Size, and PNGs', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
